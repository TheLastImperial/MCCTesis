\section{Inteligencia Artificial}

%\subsection{Historia}

El comienzo de las redes neuronales comienza en la década de 1940 con el artículo de Warren McCulloch y Walter Pitts (\cite{mcculloch1943Logical}), con el cual demostraron que es posible calcular cualquier función aritmética o lógica con el uso de redes neuronales artificiales.

En 1950 Frank Rosenblatt (\cite{rosenblatt1958Perceptron}) crea la red perceptrón, la cual es conocida como la primera aplicación práctica de las redes neuronales. Rosenblatt construyo una red perceptrón capaz de reconocer patrones. Lo cual dio inicio a la investigación del campo de las redes neuronales. No obstante, tiempo después Minsky and Papert (\cite{minsky1969Perceptrons}) demostraron que la red perceptrón solo podía resolver problemas específicos.

Con la publicación de Minsky and Papert muchos investigadores creyeron que no tenía sentido continuar con las redes neuronales. Además, de la limitante computacional de la época para realizar los experimentos que se requerían. Lo cual llevo a una pausa para la investigación de las redes neuronales por una década.

En la década de 1980 David Rumelhart y James McClelland (\cite{rumelhart1986Parallel}) crean el algoritmo de Backpropagation para el entrenamiento de las redes perceptrón multicapa, lo cual marca el renacimiento de las redes neuronales. Este algoritmo fue la respuesta al libro de Minsky y Papert de 1960, en el que plantean la limitante del uso de perceptron.
